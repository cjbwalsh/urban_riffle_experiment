---
title: "Urban riffle experiment: methods, results"
author: "Christopher J Walsh, J. Angus Webb, et al."
format: html
editor: visual
---

```{r}
#| echo: false
#| message: false
#| error: false

library(cmdstanr)
check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)
rand_seed = 9430572

source("https://tools.thewerg.unimelb.edu.au/documents/mwstr/mwstr_functions.R")
source("https://tools.thewerg.unimelb.edu.au/data/mwbugs/bugDatabaseFunctions.R")

## Load data: ultimately from OSF
# library(osfr); library(dplyr)
# if(!"data" %in% dir()){system("mkdir data")}
# if(!"wq_data_compiled.xlsx" %in% dir("data")){
# wq_files <- osf_retrieve_node("4ywvq") %>% osf_ls_files()
# osf_download(wq_files[wq_files$name == "wq_data_compiled.xlsx",], path = "data")
# }
# compile data 
sites <- readxl::read_excel("~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/data_for_model.xlsx", sheet = "sites")
samples <- readxl::read_excel("~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/data_for_model.xlsx", sheet = "samples")
biota <- readxl::read_excel("~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/data_for_model.xlsx", sheet = "biota")
subcs <- sqlQuery(paste0("SELECT site, reach FROM subcs WHERE reach IN ('",
                         paste(substr(sites$sitecode,1,nchar(sites$sitecode) -1),
                               collapse = "', '"), "');"), "mwstr")
load("~/uomShare/wergStaff/ChrisW/git-data/mwstr/mwstr_v12_corrections/imp_subcs.rda")
sites$site <- subcs$site[match(substr(sites$sitecode,1,nchar(sites$sitecode) -1),
                               subcs$reach)]
sites$ai <- imp_subcs$c_ai[match(sites$site, imp_subcs$site)]
```

## Introduction

Working methods and results for paper on the urban riffle experiment.

## Methods

### Study area and experimental design

### Riffle design and construction

### Macroinvertebrate assemblage sampling and identification

Four replicate sample units taken along the reach of each site on each date comprise a sample.

Identified to lowest practicable taxonomic level (Details)

### Environmental variable determination

Depth, velocity, substrate(?), catchment effective imperviousness

### Statistical models

We modelled the total count of taxon *j* in each sample unit, *i*, ($Y_{i,j}$) as a negative binomial distribution (given the highly skewed distributions of taxon counts) and the count of taxon *j* in a subsample of proportion $s_{i,j}$ ($c_{i,j}$) as a binomial distribution given $s_{i,j}$ and $Y_{i,j}$. Thus:

$$
\begin{align}
&Y_{i,j} \sim \textrm{Neg. Binomial}(\mu_{i,j}, \phi_{j}) \\
\\
&c_{i,j} \sim \textrm{Binomial}(s_{i,j}, Y_{i,j})
\end{align}
$$ {#eq-taxon_count_likelihood}

where $mu_{i,j}$ = the mean total count of taxon *j* in sample unit *i*, and $\phi_j$ = the dispersion parameter of the negative binomial distribution for taxon *j*.

We modelled $\mu_{i,j}$ as a linear model of 4 (5?) fixed predictors and four (5?) random predictors, thus:

$$
\begin{align}
\mu_{(i,j)} \sim  &\alpha_j + \beta\_ba_{j} * BA_i + \beta\_ci_{j} * CI_i  + \beta\_baci_{j} * BA_i * CI_i + \beta\_i_j * I_i\\
& \theta_{1(i,si)} + \theta_{2(i,sa)} + \theta_{3(i,t)}+ \epsilon_{(i,j)}
\end{align}
$$ {#eq-exp_linear_model}

where $\alpha_j$ is the model intercept for taxon *j*, $\beta\_ba_{j}$ is the before-after effect (*BA*), $\beta\_ci_{j}$ is the control-impact effect (*CI*), and $\beta\_baci_{j}$ is the interaction of the *BA* and *CI* effects. $\beta\_i_{j}$ is the the effect of catchment effective imperviousness (*I*). The $\theta$ and $\epsilon$ parameters model the error structure of the dataset. $\theta_{1(i,si)}$ models variation among samples within each site, indexed by *si*. $\theta_{2(i,sa)}$ models variation among the four sample units within each sample, indexed by *sa*. $\theta_{3(i,t)}$ models variation among samples within each sampling campaign, indexed by *t*. $\epsilon_{(i,j)}$ models extra-negative-binomial variation among all sample units.

All $\beta$ parameters were formulated as random effects drawn from community-level hyper-distributions with the mean parameters specified as normal distributions and the parameters for each species drawn from a multivariate normal distribution with a variance-covariance matrix that describes the residual associations among species.

There are full sets of L and U samples for trips 1-4. Could be worth exploring effects over the three sections, but for now, let's just stick with M samples.

```{r}
samples$seg <- substr(samples$old_samplecode,nchar(samples$old_samplecode)-1,
                      nchar(samples$old_samplecode)-1)
# aggregate(samples$smpcode, by = list(site = samples$sitecode, 
#                                      t = samples$t, seg = samples$seg), FUN = length)
samples <- samples[samples$seg == "M",]
biota_ct <- as.data.frame(ct(biota$smpcode, biota$shortcode, biota$count))
biota_ct <- biota_ct[match(samples$smpcode,row.names(biota_ct)),]
# # test with subset of taxa 
# biota_ct <- biota_ct[apply(biota_ct, 2, FUN = function(x) sum(x > 0)) > 100] #9 taxa
ss_ct <- biota_ct
for(i in 1:nrow(samples)){
  ss_ct[i,] <- samples$subsample_perc[i]/100
}
for(i in which(biota$coarsepick == 1)){
  ss_ct[row.names(ss_ct) == biota$smpcode[i], biota$shortcode[i]] <- 1
}
samples$ba <- as.numeric(as.numeric(substr(samples$old_samplecode,1,1))  > 2) 
# 0 = before, 1 = after
samples$ci <- as.numeric(sites$exp_treatment[match(samples$sitecode,sites$sitecode)] == "riffle") #0 = control, 1 = riffle
samples$baci <- samples$ba*samples$ci
samples$ai <- sites$ai[match(samples$sitecode, sites$sitecode)]
i_scaled <- scale(log10(samples$ai*100 + 0.1))
samples$i <- as.vector(i_scaled)
sites <- sites[order(sites$exp_treatment,sites$ai),]
sites$site_no <- 1:nrow(sites)
samples$site_no <- sites$site_no[match(samples$sitecode,sites$sitecode)]
samples$sample <- substr(samples$old_samplecode,1,nchar(samples$old_samplecode)-1)
sample_nos <- data.frame(sample = unique(samples$sample))
sample_nos$sample_no <- 1:nrow(sample_nos)
samples$sample_no <- sample_nos$sample_no[match(samples$sample, sample_nos$sample)]
samples$t <- as.numeric(substr(samples$old_samplecode, 1,1))
u <- model.matrix(~ ba + ci + baci + i, data = samples)
sdata <- list(n_obs = nrow(biota_ct),
              n_taxa = ncol(biota_ct),
              n_site = nrow(sites),
              n_sample = nrow(sample_nos),
              n_pred = ncol(u),
              n_t = max(samples$t),
              site_no = samples$site_no,
              samp_no = samples$sample_no,
              t = samples$t,
              u = u,
              c = as.matrix(biota_ct),
              s = as.matrix(ss_ct)
              )
mod <- cmdstan_model("nbinom_me_randomsite_fixedmatrix_baci.stan", pedantic = TRUE) 
# ni <- 7000; nt <- 4; nb <- 1000; nc <- 4  
# stanfit_i <- mod$sample(data = sdata,
#                         seed = rand_seed, chains = nc,
#                         parallel_chains = nc, iter_warmup = nb,
#                         iter_sampling = ni - nb, refresh = 200) 
# # 7000 iters 5 h 
# #  save csv files rather than the model object to use less RAM
# stanfit_i$save_output_files(
#   dir = "~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/",
#   basename = "fit_nbinom_baci_6000iter", timestamp = FALSE, random = FALSE)
# stanfit_i$sampler_diagnostics()
# saveRDS(stanfit_i, file = "~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/fit_nbinom_baci_6000iter.rds")
# stanfit_i$diagnostic_summary()
# # The above three steps required < 500 Mb RAM
# summ <- stanfit_i$summary() # This took > 2h and needed ~80 Gb Ram
# min(summ$ess_bulk,na.rm=TRUE) # 383 (near enough to ~100 per chain- the one parameter <400 was mu_gamma[4]: i.e. baci
# min(summ$ess_tail,na.rm=TRUE) # 761

m_nb_fit <- readRDS("~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/fit_nbinom_baci_6000iter.rds")
system.time({
m_nb_draws <- as.data.frame(m_nb_fit$draws(format = "df", variables = c("a_si","a_sa","a_t","gamma","phi")))
}) # 8 min
# #Extract prediction for each taxon
# pred <- list()
# system.time({
# for(i in 1:sdata$n_taxa){
#   drawsi <- m_nb_draws[grep(paste0(",",i,"]"),names(m_nb_draws))]
#   pred[[i]] <-
#     drawsi[grep("a_si",names(drawsi))][match(samples$site_no, 1:sdata$n_site)] +
#     drawsi[grep("a_sa",names(drawsi))][match(samples$sample_no, 1:sdata$n_sample)] +
#     drawsi[grep("a_t",names(drawsi))][match(samples$t, 1:sdata$n_t)] +
#       drawsi[,paste0("gamma[1,",i,"]")] %*% t(u[,1]) +
#        drawsi[,paste0("gamma[2,",i,"]")] %*% t(u[,2]) +
#        drawsi[,paste0("gamma[3,",i,"]")] %*% t(u[,3]) +
#        drawsi[,paste0("gamma[4,",i,"]")] %*% t(u[,4]) +
#        drawsi[,paste0("gamma[5,",i,"]")] %*% t(u[,5])
# }
# })  # 176 s
# names(pred) <- colnames(sdata$c)
# save(pred, file = "~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/fit_nbinom_baci_6000iter_ypred_draws.rda")
ypred_draws <- get(load("~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/fit_nbinom_baci_6000iter_ypred_draws.rda"))
# a_si_means <-  apply(m_nb_draws[,grep("a_si",names(m_nb_draws))], 2, FUN = mean)
# phi_means <- apply(m_nb_draws[,grep("phi",names(m_nb_draws))], 2, FUN = mean)
# b_means <- apply(m_nb_draws[substr(names(m_nb_draws),1,5) %in% c("gamma")], 2, FUN = mean)
prevalence <- apply(biota_ct, 2, FUN = function(x){sum(x > 0)})
n_obs_samps <- 1000
# Create a matrix of (estimated) observed total counts, given c and s
# This function takes a sample of size n (with replacement) of all integers 
# between 0 and 1 million, with each integer having the probability of T 
# (a total count) given c and s.
sample_T_given_c_s <- function(n, c, s){
sample(0:1e6, n, replace = TRUE, prob = dbinom(c,0:1e6,s))
}
  ss <- sdata$s
  ss[ss == 1 ] <- 0.99
obs <- list()
system.time({
for(i in 1:sdata$n_taxa){
  obs[[i]] <- matrix(data = NA, nrow = n_obs_samps, ncol = nrow(samples))
  for(j in 1:nrow(samples)){
    obs[[i]][,j] <- sample_T_given_c_s(n_obs_samps, sdata$c[j,i], ss[j,i])
    names(obs)[i] <- colnames(sdata$c)[i]
  }
}
}) #37 s
# save(obs, file = "~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/total_count_estimates_urban_exp_baci.rda")
load("~/uomShare/wergStaff/ChrisW/git-data/urban_riffle_experiment/model_fits/total_count_estimates_46sites.rda") #list object called obs

# prepare output matrices for estimates of T (obs), and correlations and slopes betwen O and P
cors <- matrix(nrow = n_obs_samps, ncol = length(taxa))
oe_slopes <- matrix(nrow = n_obs_samps, ncol =length(taxa))
system.time({
for(i in 1:sdata$n_taxa){
  predi <- apply(ypred_draws[[colnames(sdata$c)]],2,FUN = mean)
  y <- log(exp(aggregate(predi, by = list(site = samples_m$site_no), FUN = mean)[,-1] + 1))
  for(j in 1:n_obs_samps){
    x_raw <- log(obs[[i]][j,] + 1)
    x <- aggregate(x_raw, by = list(site = samples_m$site_no), FUN = mean)[,-1]
  cors[j,i] <- cor(x,y)
  oe_slopes[j,i] <- coefficients(lm(y ~ x))[2]
  }
  if(i %% 5 == 0)
 cat(i,"\n")
}
})
# save(cors, oe_slopes, file = "~/uomShare/wergStaff/ChrisW/git-data/species_response_46_sites/nbinom_me_fit_by_taxon.rda")
load("~/uomShare/wergStaff/ChrisW/git-data/species_response_46_sites/nbinom_me_fit_by_taxon.rda")
```
